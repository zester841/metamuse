{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca19eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata_Generation_Demo.ipynb\n",
    "\n",
    "# %% [markdown]\n",
    "# ## MetaMuse: Automated Metadata Generation Demo\n",
    "# This notebook demonstrates the complete workflow of the MetaMuse system, including:\n",
    "# 1. Sample PDF generation\n",
    "# 2. Text extraction from documents\n",
    "# 3. Semantic metadata generation\n",
    "# 4. Result visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad744e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fr0stedflake/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Install required packages\n",
    "!pip install -q fpdf pytesseract pdfminer.six python-docx spacy keybert transformers\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m nltk.downloader stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f7b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fr0stedflake/Documents/mydev/MetaMuse/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "import io\n",
    "import fitz\n",
    "import docx\n",
    "import pytesseract\n",
    "import pdfplumber\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5442e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Initialize NLP components\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "kw_model = KeyBERT()\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebb2296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample PDF created: sample_document.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Generate sample PDF\n",
    "def create_sample_pdf():\n",
    "    class PDF(FPDF):\n",
    "        def header(self):\n",
    "            self.set_font('Arial', 'B', 12)\n",
    "            self.cell(0, 10, 'MetaMuse Sample Document', 0, 1, 'C')\n",
    "        def footer(self):\n",
    "            self.set_y(-15)\n",
    "            self.set_font('Arial', 'I', 8)\n",
    "            self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "    \n",
    "    pdf = PDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('Arial', '', 12)\n",
    "    \n",
    "    sample_text = '''\n",
    "    MetaMuse is an advanced automated metadata generation system developed by Acme Corp. \n",
    "    It uses natural language processing to extract meaningful information from documents.\n",
    "    \n",
    "    Key features include:\n",
    "    - Multi-format support (PDF, DOCX, TXT)\n",
    "    - OCR capabilities for image-based content\n",
    "    - Semantic analysis of document content\n",
    "    - Structured metadata output in JSON format\n",
    "    \n",
    "    This document was generated on June 25, 2025 to demonstrate the system's capabilities.\n",
    "    '''\n",
    "    \n",
    "    pdf.multi_cell(0, 10, sample_text)\n",
    "    pdf.output(\"sample_document.pdf\")\n",
    "    print(\"Sample PDF created: sample_document.pdf\")\n",
    "\n",
    "create_sample_pdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630ae4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Document extraction functions\n",
    "def extract_pdf_text(file_path):\n",
    "    # Try text extraction first\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
    "            if text.strip(): return text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # OCR fallback\n",
    "    images = convert_from_path(file_path)\n",
    "    return \"\\n\".join(pytesseract.image_to_string(img) for img in images)\n",
    "\n",
    "def extract_docx_text(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join(para.text for para in doc.paragraphs)\n",
    "\n",
    "def extract_content(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_pdf_text(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        return extract_docx_text(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        return open(file_path).read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c9b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Metadata generation functions\n",
    "TOPIC_MAP = {\n",
    "    \"Technology\": [\"ai\", \"data\", \"cloud\", \"algorithm\", \"software\", \"digital\", \"blockchain\"],\n",
    "    \"Finance\": [\"loan\", \"investment\", \"stock\", \"bank\", \"equity\", \"credit\", \"capital\"],\n",
    "    \"Healthcare\": [\"health\", \"medical\", \"patient\", \"disease\", \"hospital\", \"treatment\"],\n",
    "    \"Education\": [\"school\", \"student\", \"learning\", \"university\", \"course\", \"teacher\"],\n",
    "    \"Environment\": [\"climate\", \"sustainability\", \"energy\", \"conservation\", \"pollution\"],\n",
    "    \"Government\": [\"policy\", \"regulation\", \"public\", \"government\", \"law\", \"administration\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f864b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_title(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    if lines:\n",
    "        candidate = lines[0]\n",
    "        if 10 <= len(candidate) <= 120 and not candidate.isupper():\n",
    "            return candidate\n",
    "    first_sentence = text.split('.')[0]\n",
    "    if 20 <= len(first_sentence) <= 150:\n",
    "        return first_sentence\n",
    "    return \"Untitled Document\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44dd5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_author(text):\n",
    "    doc = nlp(text[:2000])\n",
    "    persons = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    if persons: return persons[0]\n",
    "    match = re.search(r\"(?i)(?:by|author|written by)[: ]+\\s*(\\w+ \\w+)\", text[:1000])\n",
    "    if match: return match.group(1).title()\n",
    "    return \"Unknown Author\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b678e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_date(text):\n",
    "    doc = nlp(text[:5000])\n",
    "    dates = [ent.text for ent in doc.ents if ent.label_ == \"DATE\"]\n",
    "    if dates: return dates[0]\n",
    "    return datetime.now().strftime(\"%Y\")\n",
    "\n",
    "def extract_keyphrases(text):\n",
    "    return [kw[0] for kw in kw_model.extract_keywords(\n",
    "        text, keyphrase_ngram_range=(1, 3), stop_words=\"english\", top_n=7)]\n",
    "\n",
    "def map_topics(keyphrases):\n",
    "    topics = set()\n",
    "    for topic, keywords in TOPIC_MAP.items():\n",
    "        if any(kw in phrase.lower() for phrase in keyphrases for kw in keywords):\n",
    "            topics.add(topic)\n",
    "    return list(topics) or [\"General\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment(text):\n",
    "    doc = nlp(text)\n",
    "    pos = sum(1 for token in doc if token.sentiment > 0)\n",
    "    neg = sum(1 for token in doc if token.sentiment < 0)\n",
    "    return \"Positive\" if pos > neg else \"Negative\" if neg > pos else \"Neutral\"\n",
    "\n",
    "def analyze_readability(text):\n",
    "    words = text.split()\n",
    "    sentences = [s for s in re.split(r'[.!?]', text) if s.strip()]\n",
    "    if not sentences: return \"Unknown\"\n",
    "    avg = len(words) / len(sentences)\n",
    "    return \"Technical\" if avg > 25 else \"Standard\"\n",
    "\n",
    "def generate_summary(text):\n",
    "    if len(text.split()) < 100: \n",
    "        return \"Document too short for meaningful summary\"\n",
    "    return summarizer(text[:3000], max_length=150, min_length=30)[0]['summary_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ebff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_metadata(text):\n",
    "    return {\n",
    "        \"title\": extract_title(text),\n",
    "        \"author\": extract_author(text),\n",
    "        \"date\": extract_date(text),\n",
    "        \"keyphrases\": extract_keyphrases(text),\n",
    "        \"topics\": map_topics(extract_keyphrases(text)),\n",
    "        \"summary\": generate_summary(text),\n",
    "        \"sentiment\": analyze_sentiment(text),\n",
    "        \"readability\": analyze_readability(text),\n",
    "        \"stats\": {\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"char_count\": len(text),\n",
    "            \"sentence_count\": len([s for s in re.split(r'[.!?]', text) if s.strip()])\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d423d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from sample_document.pdf...\n",
      "\n",
      "Extracted Text Preview:\n",
      "MetaMuse Sample Document\n",
      "MetaMuse is an advanced automated metadata generation system developed by Acme Corp.\n",
      "It uses natural language processing to extract meaningful information from documents.\n",
      "Key features include:\n",
      "- Multi-format support (PDF, DOCX, TXT)\n",
      "- OCR capabilities for image-based content\n",
      "- Semantic analysis of document content\n",
      "- Structured metadata output in JSON format\n",
      "This document was generated on June 25, 2025 to demonstrate the system's capabilities.\n",
      "Page 1...\n",
      "\n",
      "Generating metadata...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Process sample document\n",
    "print(\"Extracting content from sample_document.pdf...\")\n",
    "text_content = extract_content(\"sample_document.pdf\")\n",
    "print(\"\\nExtracted Text Preview:\")\n",
    "print(text_content[:500] + \"...\\n\")\n",
    "\n",
    "# %%\n",
    "# Generate metadata\n",
    "print(\"Generating metadata...\")\n",
    "metadata = generate_metadata(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ecd14e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Metadata:\n",
      "Title: MetaMuse Sample Document\n",
      "Author: Acme Corp\n",
      "Date: June 25, 2025\n",
      "Key Phrases: sample document metamuse, document metamuse, document metamuse advanced, metamuse sample document, automated metadata generation, automated metadata, advanced automated metadata\n",
      "Topics: Technology\n",
      "Sentiment: Neutral\n",
      "Readability: Standard\n",
      "\n",
      "Summary:\n",
      "Document too short for meaningful summary\n",
      "\n",
      "Document Stats:\n",
      "- Word Count: 69\n",
      "- Character Count: 478\n",
      "- Sentence Count: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Display results\n",
    "print(\"Generated Metadata:\")\n",
    "print(f\"Title: {metadata['title']}\")\n",
    "print(f\"Author: {metadata['author']}\")\n",
    "print(f\"Date: {metadata['date']}\")\n",
    "print(f\"Key Phrases: {', '.join(metadata['keyphrases'])}\")\n",
    "print(f\"Topics: {', '.join(metadata['topics'])}\")\n",
    "print(f\"Sentiment: {metadata['sentiment']}\")\n",
    "print(f\"Readability: {metadata['readability']}\")\n",
    "print(f\"\\nSummary:\\n{metadata['summary']}\")\n",
    "print(f\"\\nDocument Stats:\")\n",
    "print(f\"- Word Count: {metadata['stats']['word_count']}\")\n",
    "print(f\"- Character Count: {metadata['stats']['char_count']}\")\n",
    "print(f\"- Sentence Count: {metadata['stats']['sentence_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d25bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata saved to sample_metadata.json\n",
      "\n",
      "JSON Metadata Output:\n",
      "{\n",
      "  \"title\": \"MetaMuse Sample Document\",\n",
      "  \"author\": \"Acme Corp\",\n",
      "  \"date\": \"June 25, 2025\",\n",
      "  \"keyphrases\": [\n",
      "    \"sample document metamuse\",\n",
      "    \"document metamuse\",\n",
      "    \"document metamuse advanced\",\n",
      "    \"metamuse sample document\",\n",
      "    \"automated metadata generation\",\n",
      "    \"automated metadata\",\n",
      "    \"advanced automated metadata\"\n",
      "  ],\n",
      "  \"topics\": [\n",
      "    \"Technology\"\n",
      "  ],\n",
      "  \"summary\": \"Document too short for meaningful summary\",\n",
      "  \"sentiment\": \"Neutral\",\n",
      "  \"readability\": \"Standard\",\n",
      "  \"stats\": {\n",
      "    \"word_count\": 69,\n",
      "    \"char_count\": 478,\n",
      "    \"sentence_count\": 4\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Save metadata to JSON\n",
    "with open(\"sample_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"\\nMetadata saved to sample_metadata.json\")\n",
    "\n",
    "# %%\n",
    "# Display JSON output\n",
    "print(\"\\nJSON Metadata Output:\")\n",
    "print(json.dumps(metadata, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
